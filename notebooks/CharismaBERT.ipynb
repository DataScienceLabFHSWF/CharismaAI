{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce80d91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from glob import glob\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62746cf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: NVIDIA GeForce RTX 3060\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# If there's a GPU available...\n",
    "if torch.cuda.is_available():    \n",
    "    # Tell PyTorch to use the GPU.    \n",
    "    device = torch.device(\"cuda:0\")\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "# If not...\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17824cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read corpora\n",
    "ambitious = pd.read_csv('../corpora/ambitious_goals.csv').drop(\"Unnamed: 0\", axis=1)\n",
    "confidence = pd.read_csv('../corpora/confidence_in_goals.csv').drop(\"Unnamed: 0\", axis=1)\n",
    "contrast = pd.read_csv('../corpora/contrast.csv').drop(\"Unnamed: 0\", axis=1)\n",
    "lists = pd.read_csv('../corpora/lists_repetitions.csv').drop(\"Unnamed: 0\", axis=1)\n",
    "similie = pd.read_csv('../corpora/metaphor_similie.csv').drop(\"Unnamed: 0\", axis=1)\n",
    "rhetoricalq = pd.read_csv('../corpora/rhetorical_question.csv').drop(\"Unnamed: 0\", axis=1)\n",
    "sentiment = pd.read_csv('../corpora/sentiment_of_the_collective.csv').drop(\"Unnamed: 0\", axis=1)\n",
    "story = pd.read_csv('../corpora/story_anecdote.csv').drop(\"Unnamed: 0\", axis=1)\n",
    "vua_metaphor = pd.read_csv('../corpora/vua_metaphor.csv')\n",
    "vua_metaphor = vua_metaphor[['sentence', 'label']].rename(columns={'label':'Metaphor', 'sentence':'Results'})\n",
    "moral_conv = pd.read_csv('../corpora/moral_convictions.csv').rename(columns={'sentence':'Results'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d95675a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>ambitious_goals</th>\n",
       "      <th>confidence_in_goals</th>\n",
       "      <th>contrast</th>\n",
       "      <th>repetition</th>\n",
       "      <th>similie</th>\n",
       "      <th>rhetorical_question</th>\n",
       "      <th>sentiment_of_the_collective</th>\n",
       "      <th>story_anecdote</th>\n",
       "      <th>Metaphor</th>\n",
       "      <th>Moral_conviction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Within the next three years, we are determined...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>By 2030, our company's revenue will surpass $1...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>In the next five years, we will establish part...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>By 2025, we will successfully reduce our energ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Within the next decade, we intend to open 100 ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84763</th>\n",
       "      <td>We cannot allow our personal biases to lead us...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84764</th>\n",
       "      <td>It is important to hold ourselves and our inst...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84765</th>\n",
       "      <td>The long-term consequences of our actions can ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84766</th>\n",
       "      <td>We must ensure that our policies do not transg...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84767</th>\n",
       "      <td>We must be vigilant against those who seek to ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>84768 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                sentence  ambitious_goals  \\\n",
       "0      Within the next three years, we are determined...              1.0   \n",
       "1      By 2030, our company's revenue will surpass $1...              1.0   \n",
       "2      In the next five years, we will establish part...              1.0   \n",
       "3      By 2025, we will successfully reduce our energ...              1.0   \n",
       "4      Within the next decade, we intend to open 100 ...              1.0   \n",
       "...                                                  ...              ...   \n",
       "84763  We cannot allow our personal biases to lead us...              0.0   \n",
       "84764  It is important to hold ourselves and our inst...              0.0   \n",
       "84765  The long-term consequences of our actions can ...              0.0   \n",
       "84766  We must ensure that our policies do not transg...              0.0   \n",
       "84767  We must be vigilant against those who seek to ...              0.0   \n",
       "\n",
       "       confidence_in_goals  contrast  repetition  similie  \\\n",
       "0                      0.0       0.0         0.0      0.0   \n",
       "1                      0.0       0.0         0.0      0.0   \n",
       "2                      0.0       0.0         0.0      0.0   \n",
       "3                      0.0       0.0         0.0      0.0   \n",
       "4                      0.0       0.0         0.0      0.0   \n",
       "...                    ...       ...         ...      ...   \n",
       "84763                  0.0       0.0         0.0      0.0   \n",
       "84764                  0.0       0.0         0.0      0.0   \n",
       "84765                  0.0       0.0         0.0      0.0   \n",
       "84766                  0.0       0.0         0.0      0.0   \n",
       "84767                  0.0       0.0         0.0      0.0   \n",
       "\n",
       "       rhetorical_question  sentiment_of_the_collective  story_anecdote  \\\n",
       "0                      0.0                          0.0             0.0   \n",
       "1                      0.0                          0.0             0.0   \n",
       "2                      0.0                          0.0             0.0   \n",
       "3                      0.0                          0.0             0.0   \n",
       "4                      0.0                          0.0             0.0   \n",
       "...                    ...                          ...             ...   \n",
       "84763                  0.0                          0.0             0.0   \n",
       "84764                  0.0                          0.0             0.0   \n",
       "84765                  0.0                          0.0             0.0   \n",
       "84766                  0.0                          0.0             0.0   \n",
       "84767                  0.0                          0.0             0.0   \n",
       "\n",
       "       Metaphor  Moral_conviction  \n",
       "0           0.0               0.0  \n",
       "1           0.0               0.0  \n",
       "2           0.0               0.0  \n",
       "3           0.0               0.0  \n",
       "4           0.0               0.0  \n",
       "...         ...               ...  \n",
       "84763       0.0               1.0  \n",
       "84764       0.0               1.0  \n",
       "84765       0.0               1.0  \n",
       "84766       0.0               1.0  \n",
       "84767       0.0               1.0  \n",
       "\n",
       "[84768 rows x 11 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs = [ambitious, confidence, contrast, lists, similie, rhetoricalq, sentiment, story, vua_metaphor, moral_conv]\n",
    "data = pd.concat(dfs, ignore_index=True).fillna(0)\n",
    "data['Results'] = data['Results'].apply(lambda x: x.replace('\"',''))\n",
    "data = data.rename(columns={'Results':'sentence'})\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a76f48ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "y = data.drop(columns=['sentence']).values #get the labels\n",
    "train, test = train_test_split(data, test_size=0.2, random_state=1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7023ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = train.sentence.values\n",
    "labels =  train.drop(columns=['sentence']).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9861a99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125cc54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "# Load the BERT tokenizer.\n",
    "print('Loading BERT tokenizer...')\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb72c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
    "input_ids = []\n",
    "# For every sentence...\n",
    "for sent in sentences:\n",
    "    # `encode` will:\n",
    "    #   (1) Tokenize the sentence.\n",
    "    #   (2) Prepend the `[CLS]` token to the start.\n",
    "    #   (3) Append the `[SEP]` token to the end.\n",
    "    #   (4) Map tokens to their IDs.\n",
    "    encoded_sent = tokenizer.encode(\n",
    "                        sent,                      # Sentence to encode.\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                        # This function also supports truncation and conversion\n",
    "                        # to pytorch tensors, but we need to do padding, so we\n",
    "                        # can't use these features :( .\n",
    "                        #max_length = 128,          # Truncate all sentences.\n",
    "                        #return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                   )\n",
    "    # Add the encoded sentence to the list.\n",
    "    input_ids.append(encoded_sent)\n",
    "# Print sentence 0, now as a list of IDs.\n",
    "print('Original: ', sentences[0])\n",
    "print('Token IDs:', input_ids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e706b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Max sentence length: ', max([len(sen) for sen in input_ids]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4848d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the distribution of sentence lengths\n",
    "sentences_len = [len(sen) for sen in sentences]\n",
    "sentences_len[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db74453d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll use the `pad_sequences` utility function to do this.\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "# Set the maximum sequence length.\n",
    "# 149 is the mean of sequence lengths\n",
    "MAX_LEN = max([len(sen) for sen in input_ids])\n",
    "print('\\nPadding/truncating all sentences to %d values...' % MAX_LEN)\n",
    "print('\\nPadding token: \"{:}\", ID: {:}'.format(tokenizer.pad_token, tokenizer.pad_token_id))\n",
    "# Pad our input tokens with value 0.\n",
    "# \"post\" indicates that we want to pad and truncate at the end of the sequence,\n",
    "# as opposed to the beginning.\n",
    "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", \n",
    "                          value=0, truncating=\"post\", padding=\"post\")\n",
    "\n",
    "labels = torch.tensor(labels,dtype=torch.long)\n",
    "print('\\Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7841087c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create attention masks\n",
    "attention_masks = []\n",
    "# For each sentence...\n",
    "for sent in input_ids:\n",
    "    \n",
    "    # Create the attention mask.\n",
    "    #   - If a token ID is 0, then it's padding, set the mask to 0.\n",
    "    #   - If a token ID is > 0, then it's a real token, set the mask to 1.\n",
    "    att_mask = [int(token_id > 0) for token_id in sent]\n",
    "    \n",
    "    # Store the attention mask for this sentence.\n",
    "    attention_masks.append(att_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5b5ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use train_test_split to split our data into train and validation sets for\n",
    "# training\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Use 90% for training and 10% for validation.\n",
    "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, labels, \n",
    "                                                            random_state=2018, test_size=0.1)\n",
    "# Do the same for the masks.\n",
    "train_masks, validation_masks, _, _ = train_test_split(attention_masks, labels,\n",
    "                                             random_state=2018, test_size=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a940ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
