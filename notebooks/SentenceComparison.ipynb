{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cab93e4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2 GPU(s) available.\n",
      "We will use the GPU: NVIDIA A100-PCIE-40GB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from glob import glob\n",
    "import torch\n",
    "# If there's a GPU available...\n",
    "if torch.cuda.is_available():    \n",
    "    # Tell PyTorch to use the GPU.    \n",
    "    device = torch.device(\"cuda\")\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "# If not...\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aacbbce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../coded_speeches/108_ak.xlsx', '../coded_speeches/10_ak.xlsx', '../coded_speeches/137_ak.xlsx', '../coded_speeches/138_ak.xlsx', '../coded_speeches/139_ak.xlsx', '../coded_speeches/140_ak.xlsx', '../coded_speeches/142_ak.xlsx', '../coded_speeches/143_ak.xlsx', '../coded_speeches/144_ak.xlsx', '../coded_speeches/145_ak.xlsx', '../coded_speeches/14_ak.xlsx', '../coded_speeches/150_ak.xlsx', '../coded_speeches/152_ak.xlsx', '../coded_speeches/153_ak.xlsx', '../coded_speeches/154_ak.xlsx', '../coded_speeches/155_ak.xlsx', '../coded_speeches/156_ak.xlsx', '../coded_speeches/157_ak.xlsx', '../coded_speeches/158_ak.xlsx', '../coded_speeches/15_ak.xlsx', '../coded_speeches/163_ak.xlsx', '../coded_speeches/164_ak.xlsx', '../coded_speeches/19_ak.xlsx', '../coded_speeches/21_ak.xlsx', '../coded_speeches/23_ak.xlsx', '../coded_speeches/24_ak.xlsx', '../coded_speeches/25_ak.xlsx', '../coded_speeches/27_ak.xlsx', '../coded_speeches/30B_ak.xlsx', '../coded_speeches/31_ak.xlsx', '../coded_speeches/32_ak.xlsx', '../coded_speeches/34_ak.xlsx', '../coded_speeches/44_ak.xlsx', '../coded_speeches/49_ak.xlsx', '../coded_speeches/50_ak.xlsx', '../coded_speeches/55_ak.xlsx', '../coded_speeches/56A_ak.xlsx', '../coded_speeches/56B_ak.xlsx', '../coded_speeches/57_ak.xlsx', '../coded_speeches/58_ak.xlsx', '../coded_speeches/59_ak.xlsx', '../coded_speeches/70_ak.xlsx', '../coded_speeches/77_ak.xlsx', '../coded_speeches/84_ak.xlsx', '../coded_speeches/85_ak.xlsx', '../coded_speeches/8_ak.xlsx', '../coded_speeches/96_ak.xlsx', '../coded_speeches/99_ak.xlsx', '../coded_speeches/9_ak.xlsx']\n"
     ]
    }
   ],
   "source": [
    "path = '../coded_speeches/'\n",
    "files = sorted(glob(path+'*_ak.xlsx'))\n",
    "print(files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d292e843",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>Metaphor</th>\n",
       "      <th>Simile</th>\n",
       "      <th>Rhetorical questions</th>\n",
       "      <th>Stories / anecdotes</th>\n",
       "      <th>Contrasts</th>\n",
       "      <th>Lists</th>\n",
       "      <th>Repetition</th>\n",
       "      <th>Moral conviction</th>\n",
       "      <th>Sentiment of the collective</th>\n",
       "      <th>Setting high expectations</th>\n",
       "      <th>Confidence in goals</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>All right, good afternoon everybody, and welco...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Im here with Paul Mounds and Roland Cook Ill i...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Just to give you our briefing.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>First of all, in terms of where we are in the ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Um, another 1200 people tested positive at a 3...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>I firmly believe our mission is the same: a sa...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>I look forward to working with you all in the ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>Thank you all for your work as public servants.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>God bless you.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>And God bless the great state of South Dakota.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5925 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              sentence  Metaphor  Simile  \\\n",
       "0    All right, good afternoon everybody, and welco...       0.0     0.0   \n",
       "1    Im here with Paul Mounds and Roland Cook Ill i...       0.0     0.0   \n",
       "2                       Just to give you our briefing.       0.0     0.0   \n",
       "3    First of all, in terms of where we are in the ...       0.0     0.0   \n",
       "4    Um, another 1200 people tested positive at a 3...       0.0     0.0   \n",
       "..                                                 ...       ...     ...   \n",
       "284  I firmly believe our mission is the same: a sa...       0.0     0.0   \n",
       "285  I look forward to working with you all in the ...       0.0     0.0   \n",
       "286    Thank you all for your work as public servants.       0.0     0.0   \n",
       "287                                     God bless you.       0.0     0.0   \n",
       "288     And God bless the great state of South Dakota.       0.0     0.0   \n",
       "\n",
       "     Rhetorical questions  Stories / anecdotes  Contrasts  Lists  Repetition  \\\n",
       "0                     0.0                  0.0        0.0    0.0         0.0   \n",
       "1                     0.0                  0.0        0.0    0.0         0.0   \n",
       "2                     0.0                  0.0        0.0    0.0         0.0   \n",
       "3                     0.0                  0.0        0.0    0.0         0.0   \n",
       "4                     0.0                  0.0        0.0    0.0         0.0   \n",
       "..                    ...                  ...        ...    ...         ...   \n",
       "284                   0.0                  0.0        0.0    0.0         0.0   \n",
       "285                   0.0                  0.0        0.0    0.0         0.0   \n",
       "286                   0.0                  0.0        0.0    0.0         0.0   \n",
       "287                   0.0                  0.0        0.0    0.0         0.0   \n",
       "288                   0.0                  0.0        0.0    0.0         0.0   \n",
       "\n",
       "     Moral conviction  Sentiment of the collective  Setting high expectations  \\\n",
       "0                 0.0                          0.0                        0.0   \n",
       "1                 0.0                          0.0                        0.0   \n",
       "2                 0.0                          0.0                        0.0   \n",
       "3                 0.0                          0.0                        0.0   \n",
       "4                 0.0                          0.0                        0.0   \n",
       "..                ...                          ...                        ...   \n",
       "284               1.0                          1.0                        0.0   \n",
       "285               1.0                          0.0                        0.0   \n",
       "286               1.0                          0.0                        0.0   \n",
       "287               1.0                          0.0                        0.0   \n",
       "288               1.0                          0.0                        0.0   \n",
       "\n",
       "     Confidence in goals  \n",
       "0                    0.0  \n",
       "1                    0.0  \n",
       "2                    0.0  \n",
       "3                    0.0  \n",
       "4                    0.0  \n",
       "..                   ...  \n",
       "284                  1.0  \n",
       "285                  1.0  \n",
       "286                  0.0  \n",
       "287                  0.0  \n",
       "288                  0.0  \n",
       "\n",
       "[5925 rows x 12 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = pd.read_excel(files[1], skiprows=7).drop(columns=['Unnamed: 0']).columns\n",
    "print(len(cols))\n",
    "data = pd.DataFrame(columns=[*cols])\n",
    "\n",
    "temp_values = []\n",
    "for file in files:\n",
    "    temp = pd.read_excel(file, skiprows=7).drop(columns=['Unnamed: 0'])\n",
    "    temp_values.append(temp)\n",
    "    \n",
    "new_cols = dict(zip(cols, [\"sentence\", \"Metaphor\",\"Simile\",\"Rhetorical questions\", \"Stories / anecdotes\", \"Contrasts\", \"Lists\", \"Repetition\", \"Moral conviction\", \"Sentiment of the collective\", \"Setting high expectations\", \"Confidence in goals\"]))\n",
    "                    # ['sentence', 'metaphor', 'simile', 'question', 'reference', 'figure_of_speech', 'lists', 'repetition', 'personal_statement', 'value_statement', 'explicit_goal', 'believe_statement']))\n",
    "\n",
    "data = pd.concat(temp_values).rename(columns = new_cols)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d86c9194",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    \"Three years later, the coffin was still full of Jello.\",\n",
    "    \"The fish dreamed of escaping the fishbowl and into the toilet where he saw his friend go.\",\n",
    "    \"The person box was packed with jelly many dozens of months later.\",\n",
    "    \"He found a leprechaun in his walnut shell.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "122931c6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/bert-base-nli-mean-tokens')\n",
    "model = AutoModel.from_pretrained('sentence-transformers/bert-base-nli-mean-tokens')\n",
    "\n",
    "tokens = {'input_ids': [], 'attention_mask': []}\n",
    "\n",
    "for sentence in data.sentence: #sentences: #\n",
    "    # encode each sentence and append to dictionary\n",
    "    new_tokens = tokenizer.encode_plus(sentence,\n",
    "                                       max_length=149,\n",
    "                                       truncation=True,\n",
    "                                       padding='max_length',\n",
    "                                       return_tensors='pt')\n",
    "    tokens['input_ids'].append(new_tokens['input_ids'][0])\n",
    "    tokens['attention_mask'].append(new_tokens['attention_mask'][0])\n",
    "\n",
    "# reformat list of tensors into single tensor\n",
    "tokens['input_ids'] = torch.stack(tokens['input_ids'])\n",
    "tokens['attention_mask'] = torch.stack(tokens['attention_mask'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bd7f23ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  2035,  2157,  ...,     0,     0,     0],\n",
       "         [  101, 10047,  2182,  ...,     0,     0,     0],\n",
       "         [  101,  2074,  2000,  ...,     0,     0,     0],\n",
       "         ...,\n",
       "         [  101,  4067,  2017,  ...,     0,     0,     0],\n",
       "         [  101,  2643, 19994,  ...,     0,     0,     0],\n",
       "         [  101,  1998,  2643,  ...,     0,     0,     0]]),\n",
       " 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0]])}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "795d2b0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['last_hidden_state', 'pooler_output'])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = model(**tokens)\n",
    "outputs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2a909110",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.7114,  0.1948,  1.7890,  ...,  0.4281,  0.4396,  0.0871],\n",
       "         [-0.8220,  0.1542,  1.7806,  ...,  0.4716,  0.5846, -0.0493],\n",
       "         [-0.1947,  0.3117,  1.8465,  ...,  0.3116,  0.4400, -0.0890],\n",
       "         ...,\n",
       "         [-0.1679,  0.1908,  1.4436,  ...,  0.3110,  0.7330, -0.2288],\n",
       "         [-0.4778,  0.3167,  1.6465,  ...,  0.3068,  0.3765,  0.0219],\n",
       "         [-0.0943,  0.1934,  1.5249,  ...,  0.2464,  0.6616, -0.3687]],\n",
       "\n",
       "        [[-0.5336,  1.2916,  1.2991,  ..., -0.3011,  0.9787,  0.6496],\n",
       "         [-0.4193,  1.4947,  0.9722,  ..., -0.3570,  1.0593,  0.4234],\n",
       "         [-0.5266,  1.2534,  1.1156,  ..., -0.1521,  0.9748,  0.5544],\n",
       "         ...,\n",
       "         [ 0.1739,  0.7020,  0.6922,  ..., -0.0747,  0.8065, -0.2749],\n",
       "         [ 0.0251,  1.0979,  1.0688,  ..., -0.2234,  0.6631, -0.0346],\n",
       "         [ 0.0693,  1.1019,  1.1264,  ..., -0.2567,  0.6959, -0.0401]],\n",
       "\n",
       "        [[ 0.0762, -0.1074,  2.3503,  ...,  0.1116, -0.3783,  0.1668],\n",
       "         [ 0.3385, -0.2229,  2.1474,  ..., -0.0405, -0.6485,  0.3977],\n",
       "         [ 0.1407, -0.1768,  1.9788,  ...,  0.4075, -0.5591,  0.0807],\n",
       "         ...,\n",
       "         [ 0.4269, -0.3559,  1.3730,  ...,  0.4986, -0.1526,  0.1333],\n",
       "         [ 0.2264, -0.2425,  1.7442,  ...,  0.4600, -0.2464, -0.3183],\n",
       "         [ 0.0754, -0.1469,  1.0472,  ...,  0.3667, -0.2170, -0.1692]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.1351,  1.1619,  1.6569,  ...,  0.4266, -0.8099,  0.5299],\n",
       "         [ 0.2934,  0.8858,  1.7668,  ...,  0.0898, -0.8235,  0.4398],\n",
       "         [ 0.1694,  0.6355,  1.6959,  ...,  0.2941, -0.5215,  0.2161],\n",
       "         ...,\n",
       "         [ 0.2786,  0.5314,  1.4746,  ...,  0.3692, -0.4436,  0.0078],\n",
       "         [ 0.1998,  0.5981,  1.3136,  ...,  0.4440, -0.5439,  0.2869],\n",
       "         [ 0.1654,  0.5234,  1.3094,  ...,  0.3621, -0.5384,  0.3197]],\n",
       "\n",
       "        [[ 0.1940,  0.5156,  2.6792,  ...,  0.6573, -0.1643,  0.1468],\n",
       "         [ 0.4764,  0.5907,  2.3374,  ...,  0.4601, -0.0247,  0.3206],\n",
       "         [ 0.6689,  0.5619,  2.7992,  ...,  0.4592, -0.1698,  0.0560],\n",
       "         ...,\n",
       "         [ 0.6327,  0.6645,  2.3551,  ...,  0.4354, -0.0496,  0.1480],\n",
       "         [ 0.4925,  0.5591,  2.1594,  ...,  0.5091,  0.0151,  0.0446],\n",
       "         [ 0.5858,  0.3561,  2.0655,  ...,  0.5714,  0.0697, -0.0513]],\n",
       "\n",
       "        [[-0.6405,  0.7914,  0.7868,  ..., -0.2193,  0.2717, -0.4206],\n",
       "         [-0.3070,  0.7126,  0.5977,  ..., -0.2695,  0.2871, -0.3454],\n",
       "         [-0.1661,  0.6360,  0.4800,  ..., -0.0812, -0.1354, -0.3421],\n",
       "         ...,\n",
       "         [-0.2195,  0.8149,  0.5192,  ...,  0.0464,  0.1785, -0.2712],\n",
       "         [-0.3568,  0.3237,  0.3498,  ..., -0.1037,  0.0244, -0.3494],\n",
       "         [-0.3502,  0.2136,  0.3060,  ..., -0.1096,  0.0554, -0.3858]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = outputs.last_hidden_state\n",
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ce892063",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5925, 149, 768])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b41d03a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5925, 149])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_mask = tokens['attention_mask']\n",
    "attention_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1bf0861c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5925, 149, 768])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = attention_mask.unsqueeze(-1).expand(embeddings.size()).float()\n",
    "mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "399b0c71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "        [[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "        [[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "        [[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "        [[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f1dae129",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5925, 149, 768])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_embeddings = embeddings * mask\n",
    "masked_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "91d63232",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.7114,  0.1948,  1.7890,  ...,  0.4281,  0.4396,  0.0871],\n",
       "         [-0.8220,  0.1542,  1.7806,  ...,  0.4716,  0.5846, -0.0493],\n",
       "         [-0.1947,  0.3117,  1.8465,  ...,  0.3116,  0.4400, -0.0890],\n",
       "         ...,\n",
       "         [-0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000, -0.0000],\n",
       "         [-0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [-0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000, -0.0000]],\n",
       "\n",
       "        [[-0.5336,  1.2916,  1.2991,  ..., -0.3011,  0.9787,  0.6496],\n",
       "         [-0.4193,  1.4947,  0.9722,  ..., -0.3570,  1.0593,  0.4234],\n",
       "         [-0.5266,  1.2534,  1.1156,  ..., -0.1521,  0.9748,  0.5544],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000,  0.0000,  ..., -0.0000,  0.0000, -0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ..., -0.0000,  0.0000, -0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ..., -0.0000,  0.0000, -0.0000]],\n",
       "\n",
       "        [[ 0.0762, -0.1074,  2.3503,  ...,  0.1116, -0.3783,  0.1668],\n",
       "         [ 0.3385, -0.2229,  2.1474,  ..., -0.0405, -0.6485,  0.3977],\n",
       "         [ 0.1407, -0.1768,  1.9788,  ...,  0.4075, -0.5591,  0.0807],\n",
       "         ...,\n",
       "         [ 0.0000, -0.0000,  0.0000,  ...,  0.0000, -0.0000,  0.0000],\n",
       "         [ 0.0000, -0.0000,  0.0000,  ...,  0.0000, -0.0000, -0.0000],\n",
       "         [ 0.0000, -0.0000,  0.0000,  ...,  0.0000, -0.0000, -0.0000]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.1351,  1.1619,  1.6569,  ...,  0.4266, -0.8099,  0.5299],\n",
       "         [ 0.2934,  0.8858,  1.7668,  ...,  0.0898, -0.8235,  0.4398],\n",
       "         [ 0.1694,  0.6355,  1.6959,  ...,  0.2941, -0.5215,  0.2161],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000, -0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000, -0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000, -0.0000,  0.0000]],\n",
       "\n",
       "        [[ 0.1940,  0.5156,  2.6792,  ...,  0.6573, -0.1643,  0.1468],\n",
       "         [ 0.4764,  0.5907,  2.3374,  ...,  0.4601, -0.0247,  0.3206],\n",
       "         [ 0.6689,  0.5619,  2.7992,  ...,  0.4592, -0.1698,  0.0560],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000, -0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000, -0.0000]],\n",
       "\n",
       "        [[-0.6405,  0.7914,  0.7868,  ..., -0.2193,  0.2717, -0.4206],\n",
       "         [-0.3070,  0.7126,  0.5977,  ..., -0.2695,  0.2871, -0.3454],\n",
       "         [-0.1661,  0.6360,  0.4800,  ..., -0.0812, -0.1354, -0.3421],\n",
       "         ...,\n",
       "         [-0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000, -0.0000],\n",
       "         [-0.0000,  0.0000,  0.0000,  ..., -0.0000,  0.0000, -0.0000],\n",
       "         [-0.0000,  0.0000,  0.0000,  ..., -0.0000,  0.0000, -0.0000]]],\n",
       "       grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b3d1e23a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5925, 768])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summed = torch.sum(masked_embeddings, 1)\n",
    "summed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cb9db463",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5925, 768])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summed_mask = torch.clamp(mask.sum(1), min=1e-9)\n",
    "summed_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ae08f52f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[22., 22., 22.,  ..., 22., 22., 22.],\n",
       "        [16., 16., 16.,  ..., 16., 16., 16.],\n",
       "        [ 9.,  9.,  9.,  ...,  9.,  9.,  9.],\n",
       "        ...,\n",
       "        [12., 12., 12.,  ..., 12., 12., 12.],\n",
       "        [ 6.,  6.,  6.,  ...,  6.,  6.,  6.],\n",
       "        [12., 12., 12.,  ..., 12., 12., 12.]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summed_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "eba98505",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4715,  0.2704,  1.7815,  ...,  0.3355,  0.4884, -0.1272],\n",
       "        [-0.2590,  1.2567,  1.0579,  ..., -0.3197,  0.9744,  0.2253],\n",
       "        [ 0.1154, -0.1998,  2.2266,  ...,  0.2250, -0.4676, -0.0172],\n",
       "        ...,\n",
       "        [ 0.2021,  0.7994,  1.4249,  ...,  0.1985, -0.8231,  0.2869],\n",
       "        [ 0.3602,  0.3985,  2.6640,  ...,  0.6533, -0.0673,  0.1198],\n",
       "        [-0.4116,  0.4883,  0.4389,  ..., -0.0656,  0.0272, -0.5090]],\n",
       "       grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_pooled = summed / summed_mask\n",
    "mean_pooled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cd9bd874",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'detach'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [42]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpairwise\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cosine_similarity\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# convert from PyTorch tensor to numpy array\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m mean_pooled \u001b[38;5;241m=\u001b[39m \u001b[43mmean_pooled\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# calculate\u001b[39;00m\n\u001b[1;32m      7\u001b[0m cosine_similarity(\n\u001b[1;32m      8\u001b[0m     [mean_pooled[\u001b[38;5;241m0\u001b[39m]],\n\u001b[1;32m      9\u001b[0m     mean_pooled[\u001b[38;5;241m1\u001b[39m:]\n\u001b[1;32m     10\u001b[0m )\u001b[38;5;241m.\u001b[39margmax()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'detach'"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# convert from PyTorch tensor to numpy array\n",
    "mean_pooled = mean_pooled.detach().numpy()\n",
    "\n",
    "# calculate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "79b44520",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.74474734, 0.7056477 , 0.74258924, 0.832778  , 0.74243563,\n",
       "       0.757377  ], dtype=float32)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(\n",
    "    [mean_pooled[0]],\n",
    "    mean_pooled[1:]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "acc10f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarities = pd.DataFrame(cosine_similarity(\n",
    "    mean_pooled\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "79e5fa7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>5915</th>\n",
       "      <th>5916</th>\n",
       "      <th>5917</th>\n",
       "      <th>5918</th>\n",
       "      <th>5919</th>\n",
       "      <th>5920</th>\n",
       "      <th>5921</th>\n",
       "      <th>5922</th>\n",
       "      <th>5923</th>\n",
       "      <th>5924</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.482315</td>\n",
       "      <td>0.539548</td>\n",
       "      <td>0.270033</td>\n",
       "      <td>0.321339</td>\n",
       "      <td>0.372275</td>\n",
       "      <td>0.209080</td>\n",
       "      <td>0.420433</td>\n",
       "      <td>0.329566</td>\n",
       "      <td>0.399162</td>\n",
       "      <td>...</td>\n",
       "      <td>0.382432</td>\n",
       "      <td>0.265092</td>\n",
       "      <td>0.389649</td>\n",
       "      <td>0.422999</td>\n",
       "      <td>0.525015</td>\n",
       "      <td>0.455656</td>\n",
       "      <td>0.591651</td>\n",
       "      <td>0.501383</td>\n",
       "      <td>0.435362</td>\n",
       "      <td>0.406074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.482315</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.380242</td>\n",
       "      <td>0.420791</td>\n",
       "      <td>0.285500</td>\n",
       "      <td>0.378000</td>\n",
       "      <td>0.279478</td>\n",
       "      <td>0.287651</td>\n",
       "      <td>0.335097</td>\n",
       "      <td>0.236579</td>\n",
       "      <td>...</td>\n",
       "      <td>0.109086</td>\n",
       "      <td>0.285455</td>\n",
       "      <td>0.404042</td>\n",
       "      <td>0.293651</td>\n",
       "      <td>0.338417</td>\n",
       "      <td>0.208758</td>\n",
       "      <td>0.309797</td>\n",
       "      <td>0.199518</td>\n",
       "      <td>0.263104</td>\n",
       "      <td>0.283418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.539548</td>\n",
       "      <td>0.380242</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.508724</td>\n",
       "      <td>0.034013</td>\n",
       "      <td>0.483690</td>\n",
       "      <td>0.170454</td>\n",
       "      <td>0.597477</td>\n",
       "      <td>0.250988</td>\n",
       "      <td>0.334286</td>\n",
       "      <td>...</td>\n",
       "      <td>0.525182</td>\n",
       "      <td>0.201829</td>\n",
       "      <td>0.476673</td>\n",
       "      <td>0.327965</td>\n",
       "      <td>0.199285</td>\n",
       "      <td>0.310883</td>\n",
       "      <td>0.397520</td>\n",
       "      <td>0.421711</td>\n",
       "      <td>0.532285</td>\n",
       "      <td>0.271947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.270033</td>\n",
       "      <td>0.420791</td>\n",
       "      <td>0.508724</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.131673</td>\n",
       "      <td>0.566762</td>\n",
       "      <td>0.260344</td>\n",
       "      <td>0.402828</td>\n",
       "      <td>0.233060</td>\n",
       "      <td>0.413735</td>\n",
       "      <td>...</td>\n",
       "      <td>0.474286</td>\n",
       "      <td>0.183959</td>\n",
       "      <td>0.413786</td>\n",
       "      <td>0.324119</td>\n",
       "      <td>0.179560</td>\n",
       "      <td>0.145713</td>\n",
       "      <td>0.196488</td>\n",
       "      <td>0.145052</td>\n",
       "      <td>0.337623</td>\n",
       "      <td>0.203689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.321339</td>\n",
       "      <td>0.285500</td>\n",
       "      <td>0.034013</td>\n",
       "      <td>0.131673</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.385955</td>\n",
       "      <td>0.436009</td>\n",
       "      <td>0.259814</td>\n",
       "      <td>0.485782</td>\n",
       "      <td>0.302233</td>\n",
       "      <td>...</td>\n",
       "      <td>0.046259</td>\n",
       "      <td>0.248319</td>\n",
       "      <td>0.309219</td>\n",
       "      <td>0.340503</td>\n",
       "      <td>0.517919</td>\n",
       "      <td>0.181491</td>\n",
       "      <td>0.373292</td>\n",
       "      <td>0.192808</td>\n",
       "      <td>0.166256</td>\n",
       "      <td>0.249057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5920</th>\n",
       "      <td>0.455656</td>\n",
       "      <td>0.208758</td>\n",
       "      <td>0.310883</td>\n",
       "      <td>0.145713</td>\n",
       "      <td>0.181491</td>\n",
       "      <td>0.313879</td>\n",
       "      <td>0.341948</td>\n",
       "      <td>0.285803</td>\n",
       "      <td>0.147127</td>\n",
       "      <td>0.642333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.558408</td>\n",
       "      <td>0.479228</td>\n",
       "      <td>0.394025</td>\n",
       "      <td>0.313824</td>\n",
       "      <td>0.497622</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.517000</td>\n",
       "      <td>0.607723</td>\n",
       "      <td>0.631624</td>\n",
       "      <td>0.720904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5921</th>\n",
       "      <td>0.591651</td>\n",
       "      <td>0.309797</td>\n",
       "      <td>0.397520</td>\n",
       "      <td>0.196488</td>\n",
       "      <td>0.373292</td>\n",
       "      <td>0.382894</td>\n",
       "      <td>0.335793</td>\n",
       "      <td>0.419410</td>\n",
       "      <td>0.176808</td>\n",
       "      <td>0.429384</td>\n",
       "      <td>...</td>\n",
       "      <td>0.307559</td>\n",
       "      <td>0.311661</td>\n",
       "      <td>0.369906</td>\n",
       "      <td>0.392328</td>\n",
       "      <td>0.676277</td>\n",
       "      <td>0.517000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.543064</td>\n",
       "      <td>0.403320</td>\n",
       "      <td>0.394194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5922</th>\n",
       "      <td>0.501383</td>\n",
       "      <td>0.199518</td>\n",
       "      <td>0.421711</td>\n",
       "      <td>0.145052</td>\n",
       "      <td>0.192808</td>\n",
       "      <td>0.371203</td>\n",
       "      <td>0.224236</td>\n",
       "      <td>0.396928</td>\n",
       "      <td>0.148387</td>\n",
       "      <td>0.461251</td>\n",
       "      <td>...</td>\n",
       "      <td>0.492570</td>\n",
       "      <td>0.325035</td>\n",
       "      <td>0.455352</td>\n",
       "      <td>0.465523</td>\n",
       "      <td>0.417250</td>\n",
       "      <td>0.607723</td>\n",
       "      <td>0.543064</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.648152</td>\n",
       "      <td>0.524719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5923</th>\n",
       "      <td>0.435362</td>\n",
       "      <td>0.263104</td>\n",
       "      <td>0.532285</td>\n",
       "      <td>0.337623</td>\n",
       "      <td>0.166256</td>\n",
       "      <td>0.358936</td>\n",
       "      <td>0.210689</td>\n",
       "      <td>0.401272</td>\n",
       "      <td>0.287279</td>\n",
       "      <td>0.586112</td>\n",
       "      <td>...</td>\n",
       "      <td>0.659249</td>\n",
       "      <td>0.225752</td>\n",
       "      <td>0.571199</td>\n",
       "      <td>0.257648</td>\n",
       "      <td>0.399903</td>\n",
       "      <td>0.631624</td>\n",
       "      <td>0.403320</td>\n",
       "      <td>0.648152</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.580427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5924</th>\n",
       "      <td>0.406074</td>\n",
       "      <td>0.283418</td>\n",
       "      <td>0.271947</td>\n",
       "      <td>0.203689</td>\n",
       "      <td>0.249057</td>\n",
       "      <td>0.329210</td>\n",
       "      <td>0.293475</td>\n",
       "      <td>0.291811</td>\n",
       "      <td>0.186294</td>\n",
       "      <td>0.441700</td>\n",
       "      <td>...</td>\n",
       "      <td>0.489902</td>\n",
       "      <td>0.611454</td>\n",
       "      <td>0.453770</td>\n",
       "      <td>0.295411</td>\n",
       "      <td>0.473149</td>\n",
       "      <td>0.720904</td>\n",
       "      <td>0.394194</td>\n",
       "      <td>0.524719</td>\n",
       "      <td>0.580427</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5925 rows Ã— 5925 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6     \\\n",
       "0     1.000000  0.482315  0.539548  0.270033  0.321339  0.372275  0.209080   \n",
       "1     0.482315  1.000000  0.380242  0.420791  0.285500  0.378000  0.279478   \n",
       "2     0.539548  0.380242  1.000000  0.508724  0.034013  0.483690  0.170454   \n",
       "3     0.270033  0.420791  0.508724  1.000000  0.131673  0.566762  0.260344   \n",
       "4     0.321339  0.285500  0.034013  0.131673  1.000000  0.385955  0.436009   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "5920  0.455656  0.208758  0.310883  0.145713  0.181491  0.313879  0.341948   \n",
       "5921  0.591651  0.309797  0.397520  0.196488  0.373292  0.382894  0.335793   \n",
       "5922  0.501383  0.199518  0.421711  0.145052  0.192808  0.371203  0.224236   \n",
       "5923  0.435362  0.263104  0.532285  0.337623  0.166256  0.358936  0.210689   \n",
       "5924  0.406074  0.283418  0.271947  0.203689  0.249057  0.329210  0.293475   \n",
       "\n",
       "          7         8         9     ...      5915      5916      5917  \\\n",
       "0     0.420433  0.329566  0.399162  ...  0.382432  0.265092  0.389649   \n",
       "1     0.287651  0.335097  0.236579  ...  0.109086  0.285455  0.404042   \n",
       "2     0.597477  0.250988  0.334286  ...  0.525182  0.201829  0.476673   \n",
       "3     0.402828  0.233060  0.413735  ...  0.474286  0.183959  0.413786   \n",
       "4     0.259814  0.485782  0.302233  ...  0.046259  0.248319  0.309219   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "5920  0.285803  0.147127  0.642333  ...  0.558408  0.479228  0.394025   \n",
       "5921  0.419410  0.176808  0.429384  ...  0.307559  0.311661  0.369906   \n",
       "5922  0.396928  0.148387  0.461251  ...  0.492570  0.325035  0.455352   \n",
       "5923  0.401272  0.287279  0.586112  ...  0.659249  0.225752  0.571199   \n",
       "5924  0.291811  0.186294  0.441700  ...  0.489902  0.611454  0.453770   \n",
       "\n",
       "          5918      5919      5920      5921      5922      5923      5924  \n",
       "0     0.422999  0.525015  0.455656  0.591651  0.501383  0.435362  0.406074  \n",
       "1     0.293651  0.338417  0.208758  0.309797  0.199518  0.263104  0.283418  \n",
       "2     0.327965  0.199285  0.310883  0.397520  0.421711  0.532285  0.271947  \n",
       "3     0.324119  0.179560  0.145713  0.196488  0.145052  0.337623  0.203689  \n",
       "4     0.340503  0.517919  0.181491  0.373292  0.192808  0.166256  0.249057  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "5920  0.313824  0.497622  1.000000  0.517000  0.607723  0.631624  0.720904  \n",
       "5921  0.392328  0.676277  0.517000  1.000000  0.543064  0.403320  0.394194  \n",
       "5922  0.465523  0.417250  0.607723  0.543064  1.000000  0.648152  0.524719  \n",
       "5923  0.257648  0.399903  0.631624  0.403320  0.648152  1.000000  0.580427  \n",
       "5924  0.295411  0.473149  0.720904  0.394194  0.524719  0.580427  1.000000  \n",
       "\n",
       "[5925 rows x 5925 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "099017e8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>5915</th>\n",
       "      <th>5916</th>\n",
       "      <th>5917</th>\n",
       "      <th>5918</th>\n",
       "      <th>5919</th>\n",
       "      <th>5920</th>\n",
       "      <th>5921</th>\n",
       "      <th>5922</th>\n",
       "      <th>5923</th>\n",
       "      <th>5924</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5920</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.720904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5921</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5922</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5923</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5924</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.720904</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5925 rows Ã— 5925 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0     1     2     3     4     5     6     7     8     9     ...  5915  \\\n",
       "0      NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   NaN   \n",
       "1      NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   NaN   \n",
       "2      NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   NaN   \n",
       "3      NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   NaN   \n",
       "4      NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   NaN   \n",
       "...    ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   ...   \n",
       "5920   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   NaN   \n",
       "5921   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   NaN   \n",
       "5922   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   NaN   \n",
       "5923   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   NaN   \n",
       "5924   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   NaN   \n",
       "\n",
       "      5916  5917  5918  5919      5920  5921  5922  5923      5924  \n",
       "0      NaN   NaN   NaN   NaN       NaN   NaN   NaN   NaN       NaN  \n",
       "1      NaN   NaN   NaN   NaN       NaN   NaN   NaN   NaN       NaN  \n",
       "2      NaN   NaN   NaN   NaN       NaN   NaN   NaN   NaN       NaN  \n",
       "3      NaN   NaN   NaN   NaN       NaN   NaN   NaN   NaN       NaN  \n",
       "4      NaN   NaN   NaN   NaN       NaN   NaN   NaN   NaN       NaN  \n",
       "...    ...   ...   ...   ...       ...   ...   ...   ...       ...  \n",
       "5920   NaN   NaN   NaN   NaN       NaN   NaN   NaN   NaN  0.720904  \n",
       "5921   NaN   NaN   NaN   NaN       NaN   NaN   NaN   NaN       NaN  \n",
       "5922   NaN   NaN   NaN   NaN       NaN   NaN   NaN   NaN       NaN  \n",
       "5923   NaN   NaN   NaN   NaN       NaN   NaN   NaN   NaN       NaN  \n",
       "5924   NaN   NaN   NaN   NaN  0.720904   NaN   NaN   NaN       NaN  \n",
       "\n",
       "[5925 rows x 5925 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarities[(similarities>0.7) & (similarities!=1.0) & (similarities<0.999999)] #rounding errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750fadaf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
